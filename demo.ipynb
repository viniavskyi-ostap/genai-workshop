{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e9d9fb-6fb6-4e2b-8992-ac8bfcd288d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import diffusers\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from diffusers import (\n",
    "    StableDiffusionPipeline, StableDiffusionImg2ImgPipeline,\n",
    "    StableDiffusionInpaintPipeline, StableDiffusionControlNetInpaintPipeline,\n",
    "    ControlNetModel\n",
    ")\n",
    "from diffusers.utils import load_image, make_image_grid\n",
    "\n",
    "\n",
    "try:\n",
    "    import xformers\n",
    "    xformers_loaded = True\n",
    "except ImportError:\n",
    "    xformers_loaded = False\n",
    "\n",
    "print(f'{xformers_loaded=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8837e3-b125-47dc-9a14-c55a47899f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2093921f-0137-4435-8140-bb4471cb4715",
   "metadata": {},
   "source": [
    "### Text2Img genereration pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1707f95-2285-4318-88c0-a9efe6277244",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe_gen = StableDiffusionPipeline.from_pretrained(\n",
    "    \"SG161222/Realistic_Vision_V5.1_noVAE\",\n",
    "    torch_dtype=torch.float16,\n",
    "    use_safetensors=True,\n",
    ").to(device)\n",
    "\n",
    "if xformers_loaded:\n",
    "    pipe_gen.enable_xformers_memory_efficient_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6640fde1-9a36-4aaf-b326-d88fdc5d73fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator()\n",
    "generator.manual_seed(42)\n",
    "\n",
    "output_images = pipe_gen(\n",
    "    prompt='woman in black dress, high quality, detailed, 4k',\n",
    "    negative_prompt='monochrome, lowres, bad anatomy, worst quality, low quality',\n",
    "    height=512, width=512,\n",
    "    num_inference_steps=20, guidance_scale=7.5,\n",
    "    num_images_per_prompt=4,\n",
    "    generator=generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4ab864-c7fc-405f-a9e4-47635bfee442",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_image_grid(output_images.images, rows=1, cols=4, resize=384)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3c41fb-b6d2-4802-a552-b3dd02a08e83",
   "metadata": {},
   "source": [
    "### SDEdit - img2img translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6696d257-72d4-4c71-8d0d-e6ef769d32a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_img2img = StableDiffusionImg2ImgPipeline(\n",
    "    scheduler=pipe_gen.scheduler,\n",
    "    text_encoder=pipe_gen.text_encoder,\n",
    "    tokenizer=pipe_gen.tokenizer,\n",
    "    unet=pipe_gen.unet,\n",
    "    vae=pipe_gen.vae,\n",
    "    safety_checker=pipe_gen.safety_checker,\n",
    "    feature_extractor=pipe_gen.feature_extractor\n",
    ").to(device)\n",
    "\n",
    "if xformers_loaded:\n",
    "    pipe_img2img.enable_xformers_memory_efficient_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158ecd9b-7f1a-4225-a0ea-1dccf1b93016",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.manual_seed(1)\n",
    "\n",
    "strengths = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "output_images_img2img = []\n",
    "\n",
    "for s in strengths:\n",
    "    out = pipe_img2img(\n",
    "        image=output_images.images[1],\n",
    "        strength=s,\n",
    "        prompt='woman in green dress, high quality, detailed, 4k',\n",
    "        negative_prompt='monochrome, lowres, bad anatomy, worst quality, low quality',\n",
    "        num_inference_steps=20, guidance_scale=7.5,\n",
    "        num_images_per_prompt=1,\n",
    "        generator=generator\n",
    "    )\n",
    "    output_images_img2img.append(out.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f378730-51ce-4da5-9cbb-88e46a4a4e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_image_grid(output_images_img2img, rows=2, cols=4, resize=384)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79a1069-e84d-41b6-a731-95229fed71fd",
   "metadata": {},
   "source": [
    "### Inpainting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7257f042-4811-4d14-81fb-aebd627608d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe_inpainting = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "    \"Uminosachi/realisticVisionV51_v51VAE-inpainting\",\n",
    "    torch_dtype=torch.float16,\n",
    "    use_safetensors=True,\n",
    ").to(device)\n",
    "\n",
    "if xformers_loaded:\n",
    "    pipe_inpainting.enable_xformers_memory_efficient_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0d9b77-10a4-48cb-99b3-77c6e8b92d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('./data/red_dress_image.jpg')\n",
    "mask = Image.open('./data/red_dress_mask.png')\n",
    "\n",
    "# extract dress mask\n",
    "mask = np.array(mask)\n",
    "mask = (mask == 6).astype(np.uint8) * 255\n",
    "# optional dilation\n",
    "mask = cv2.dilate(mask, kernel=np.ones((5, 5)))\n",
    "mask = Image.fromarray(mask)\n",
    "\n",
    "make_image_grid([image, mask], rows=1, cols=2, resize=384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c33442b-d78d-40d6-9ad1-93652ee8040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.manual_seed(2)\n",
    "\n",
    "out = pipe_inpainting(\n",
    "    image=image,\n",
    "    mask_image=mask,\n",
    "    strength=1.,\n",
    "    prompt='woman in green dress, high quality, detailed, 4k',\n",
    "    negative_prompt='monochrome, lowres, bad anatomy, worst quality, low quality',\n",
    "    num_inference_steps=20, guidance_scale=7.5,\n",
    "    num_images_per_prompt=4,\n",
    "    generator=generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da9e979-fa0b-4e2c-9dba-e74b29c74253",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_image_grid(out.images, rows=1, cols=4, resize=384)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60629aa6-8c7b-4824-a417-63a1180380bb",
   "metadata": {},
   "source": [
    "### Inpainting with ControlNet for edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b63997-ca07-4b30-b78b-a68ba29359b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "controlnet = ControlNetModel.from_pretrained(\n",
    "    \"lllyasviel/sd-controlnet-canny\", \n",
    "    torch_dtype=torch.float16, \n",
    "    use_safetensors=True)\n",
    "\n",
    "pipe_inpainting_controlnet = StableDiffusionControlNetInpaintPipeline(\n",
    "    scheduler=pipe_inpainting.scheduler,\n",
    "    text_encoder=pipe_inpainting.text_encoder,\n",
    "    tokenizer=pipe_inpainting.tokenizer,\n",
    "    unet=pipe_inpainting.unet,\n",
    "    vae=pipe_inpainting.vae,\n",
    "    safety_checker=pipe_inpainting.safety_checker,\n",
    "    feature_extractor=pipe_inpainting.feature_extractor,\n",
    "    controlnet=controlnet\n",
    ").to(device)\n",
    "\n",
    "if xformers_loaded:\n",
    "    pipe_inpainting_controlnet.enable_xformers_memory_efficient_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9876554-4e4b-4f51-9415-00512adc450d",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_image = np.rot90(np.array(Image.open('./data/pattern.jpeg')))\n",
    "\n",
    "control_image_edge = cv2.Canny(control_image, 100, 200)\n",
    "control_image_edge = control_image_edge[:, :, None]\n",
    "control_image_edge = np.concatenate([control_image_edge, control_image_edge, control_image_edge], axis=2)\n",
    "\n",
    "control_image = Image.fromarray(control_image).resize(image.size)\n",
    "control_image_edge = Image.fromarray(control_image_edge).resize(image.size)\n",
    "\n",
    "make_image_grid([control_image, control_image_edge], rows=1, cols=2, resize=384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b07b53b-a1fd-4310-afd0-6b2b30717862",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.manual_seed(3)\n",
    "\n",
    "out = pipe_inpainting_controlnet(\n",
    "    image=image,\n",
    "    mask_image=mask,\n",
    "    control_image=control_image_edge,\n",
    "    strength=1.,\n",
    "    prompt='woman in dark dress, high quality, detailed, 4k',\n",
    "    negative_prompt='monochrome, lowres, bad anatomy, worst quality, low quality',\n",
    "    num_inference_steps=20, guidance_scale=7.5,\n",
    "    num_images_per_prompt=4,\n",
    "    generator=generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7e9a5f-5498-4811-9269-797e393acf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_image_grid(out.images, rows=1, cols=4, resize=384)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cc31a0-adc7-4f45-83f9-1d23675641a1",
   "metadata": {},
   "source": [
    "### IP-adapter for Image prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c64e82-fc85-486b-b1e7-303df0ffb3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_inpainting.load_ip_adapter(\n",
    "    \"h94/IP-Adapter\",\n",
    "    subfolder=\"models\", \n",
    "    weight_name=\"ip-adapter_sd15.safetensors\")\n",
    "pipe_inpainting.set_ip_adapter_scale(0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f309f6-b946-49a7-9466-4968158d8ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.manual_seed(4)\n",
    "\n",
    "ip_adapter_image = Image.open('./data/casual.jpeg')\n",
    "\n",
    "out = pipe_inpainting(\n",
    "    image=image,\n",
    "    mask_image=mask,\n",
    "    strength=1.,\n",
    "    ip_adapter_image=ip_adapter_image,\n",
    "    prompt='woman, high quality, detailed, 4k',\n",
    "    negative_prompt='monochrome, lowres, bad anatomy, worst quality, low quality',\n",
    "    num_inference_steps=20, guidance_scale=7.5,\n",
    "    num_images_per_prompt=4,\n",
    "    generator=generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ef8fd1-fc64-4348-96d0-339c320c7266",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_image_grid([ip_adapter_image] + out.images, rows=1, cols=5, resize=384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbe5d86-f4c0-4e2b-bb4d-5adf69a3e169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
